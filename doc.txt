def generate_output():
    # Read data from master.xlsx, Takara.xlsx, and prodman.xlsx
    master = pd.read_excel('master.xlsx')
    Takara = pd.read_excel('Takara.xlsx')
    prodman = pd.read_excel('prodman.xlsx')

    # Merge data from prodman.xlsx and takara.xlsx based on 'obligorId' and 'currentObligorId'
    abc_df = pd.merge(master, Takara, left_on='Counterparty RDM Id', right_on='externalId', how='left')
    merged_output_df = pd.merge(abc_df, prodman, left_on='currentObligorRdmId', right_on='ObligorId', how='left')

    # Define selected columns
    selected_columns = ['Operation Type', 'Trade Date', 'Trade Price', 'Value Date', 'Primary Original Quantity', 'Settlement Instrument Name', 'ISIN Primary Instrument Reference', 'Primary Instrument Long Name', 'SMO Trade Reference', 'Internal Status Narrative', 'Sales Person Name','currentObligorRdmId', 'currentObligorFullName', 'CashScore']

    # Reorder columns and select required columns
    output_df = merged_output_df[selected_columns]

    output_df=output_df.drop_duplicates()

    # Define new columns
    new_columns = ['CBBT_PX_ASK', 'Economic Impact', 'LQA (Liq Score)', 'Days Elapsed']

    # Define the desired column order
    custom_column_order = ['currentObligorRdmId','currentObligorFullName', 'CashScore','Operation Type', 'Trade Date', 'Trade Price','CBBT_PX_ASK', 'Economic Impact', 'LQA (Liq Score)','Value Date','Days Elapsed','Primary Original Quantity', 'Settlement Instrument Name', 'ISIN Primary Instrument Reference', 'Primary Instrument Long Name', 'SMO Trade Reference', 'Internal Status Narrative', 'Sales Person Name']

    # Insert new columns at specific position
    for i, col in enumerate(new_columns, start=1):
        output_df.insert(output_df.columns.get_loc('currentObligorRdmId') + i, col, '')

    # Add dummy data to new columns
    output_df['CBBT_PX_ASK'] = [random.randint(1, 100) for _ in range(len(output_df))]
    output_df['Economic Impact'] = [random.uniform(-10000, 10000) for _ in range(len(output_df))]  # Generating some negative values for testing
    output_df['LQA (Liq Score)'] = [random.uniform(1000, 10000) for _ in range(len(output_df))]

    # Convert dates to string format
    output_df['Trade Date'] = pd.to_datetime(output_df['Trade Date']).dt.strftime('%Y-%m-%d')
    output_df['Value Date'] = pd.to_datetime(output_df['Value Date']).dt.strftime('%Y-%m-%d')

    # Round 'Economic Impact' and 'LQA (Liq Score)' columns to integers
    output_df['Economic Impact'] = output_df['Economic Impact'].astype(int)
    output_df['LQA (Liq Score)'] = output_df['LQA (Liq Score)'].astype(int)
    output_df['Trade Price'] = output_df['Trade Price'].round(2)

    # Calculate days elapsed
    output_df['Value Date'] = pd.to_datetime(output_df['Value Date'])
    today = datetime.today()
    output_df['Days Elapsed'] = (today - output_df['Value Date']).dt.days - 1

    # Fill NA for empty cells in new columns
    output_df[['currentObligorRdmId', 'CashScore']] = output_df[['currentObligorRdmId', 'CashScore']].fillna('NA')

    # Reorder columns based on custom_column_order
    output_df = output_df[custom_column_order]

    # Define output filename
    output_filename = 'output.xlsx'

    # Write data to Excel file
    with pd.ExcelWriter(output_filename) as writer:
        output_df.to_excel(writer, index=False, sheet_name='All Data')

        # Filter data where operation type is Buy
        buy_df = output_df[output_df['Operation Type'].str.contains('BUY')]
        buy_df.to_excel(writer, index=False, sheet_name='Buy Data')

        # Filter data where operation type is Sell
        sell_df = output_df[output_df['Operation Type'].str.contains('SELL')]
        sell_df.to_excel(writer, index=False, sheet_name='Sell Data')

    # Open the Excel file
    wb = load_workbook(output_filename)
